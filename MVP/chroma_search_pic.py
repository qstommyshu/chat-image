"""
è°ƒè¯•ç‰ˆæœ¬ï¼šåˆ†æä¸ºä»€ä¹ˆæ‰¾ä¸åˆ°JPGå›¾ç‰‡
"""
import os
from dotenv import load_dotenv
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from langchain.schema import Document
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# è½½å…¥ç¯å¢ƒå˜é‡
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")

# 1. è¯»å– HTML
with open('apple_page.html', 'r', encoding='utf-8') as f:
    html = f.read()

print(f"HTMLæ–‡ä»¶å¤§å°: {len(html)} å­—ç¬¦")

soup = BeautifulSoup(html, 'html.parser')
base_url = 'https://www.apple.com'

# 2. è¯¦ç»†åˆ†ææ‰€æœ‰å›¾ç‰‡å’Œsourceæ ‡ç­¾
print("\n=== è¯¦ç»†åˆ†ææ‰€æœ‰å›¾ç‰‡å’Œsourceæ ‡ç­¾ ===")
all_imgs = soup.find_all('img')
all_sources = soup.find_all('source')
print(f"æ‰¾åˆ° {len(all_imgs)} ä¸ª img æ ‡ç­¾")
print(f"æ‰¾åˆ° {len(all_sources)} ä¸ª source æ ‡ç­¾")

def get_image_format(url):
    """è·å–å›¾ç‰‡æ ¼å¼"""
    url_lower = url.lower()
    if any(ext in url_lower for ext in ['.jpg', '.jpeg']):
        return 'jpg'
    elif '.png' in url_lower:
        return 'png'
    elif '.svg' in url_lower:
        return 'svg'
    elif '.webp' in url_lower:
        return 'webp'
    elif '.gif' in url_lower:
        return 'gif'
    else:
        return 'unknown'

def extract_context_from_source(source_tag):
    """ä»sourceæ ‡ç­¾æå–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    context_parts = []
    
    # 1. sourceæ ‡ç­¾çš„å±æ€§
    media_attr = source_tag.get('media', '')
    if media_attr:
        context_parts.append(f"Media: {media_attr}")
    
    # 2. æŸ¥æ‰¾å…³è”çš„pictureå…ƒç´ 
    picture = source_tag.find_parent('picture')
    if picture:
        # åœ¨pictureä¸­æŸ¥æ‰¾imgæ ‡ç­¾
        img_in_picture = picture.find('img')
        if img_in_picture:
            alt_text = img_in_picture.get('alt', '')
            title_text = img_in_picture.get('title', '')
            class_attr = ' '.join(img_in_picture.get('class', []))
            
            if alt_text:
                context_parts.append(f"Alt: {alt_text}")
            if title_text:
                context_parts.append(f"Title: {title_text}")
            if class_attr:
                context_parts.append(f"Class: {class_attr}")
    
    # 3. æŸ¥æ‰¾çˆ¶å…ƒç´ çš„æ–‡æœ¬å†…å®¹
    parent = source_tag.parent
    if parent:
        parent_text = parent.get_text(strip=True)
        if parent_text and len(parent_text) < 300:
            context_parts.append(f"Parent text: {parent_text}")
    
    # 4. æŸ¥æ‰¾å‘¨å›´çš„æ–‡æœ¬
    for sibling in source_tag.find_next_siblings(text=True)[:2]:
        sibling_text = sibling.strip()
        if sibling_text and len(sibling_text) < 100:
            context_parts.append(f"Next text: {sibling_text}")
            break
    
    return " | ".join(context_parts) if context_parts else str(source_tag)

def extract_context(img_tag):
    """æå–å›¾ç‰‡çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    context_parts = []
    
    # 1. imgæ ‡ç­¾æœ¬èº«çš„å±æ€§
    alt_text = img_tag.get('alt', '')
    title_text = img_tag.get('title', '')
    class_attr = ' '.join(img_tag.get('class', []))
    
    if alt_text:
        context_parts.append(f"Alt: {alt_text}")
    if title_text:
        context_parts.append(f"Title: {title_text}")
    if class_attr:
        context_parts.append(f"Class: {class_attr}")
    
    # 2. çˆ¶å…ƒç´ çš„æ–‡æœ¬å†…å®¹
    parent = img_tag.parent
    if parent:
        parent_text = parent.get_text(strip=True)
        if parent_text and len(parent_text) < 200:
            context_parts.append(f"Parent text: {parent_text}")
    
    # 3. æŸ¥æ‰¾ç›¸é‚»çš„æ–‡æœ¬å…ƒç´ 
    for sibling in img_tag.find_next_siblings(text=True)[:2]:
        sibling_text = sibling.strip()
        if sibling_text and len(sibling_text) < 100:
            context_parts.append(f"Next text: {sibling_text}")
            break
    
    for sibling in img_tag.find_previous_siblings(text=True)[:2]:
        sibling_text = sibling.strip()
        if sibling_text and len(sibling_text) < 100:
            context_parts.append(f"Prev text: {sibling_text}")
            break
    
    return " | ".join(context_parts) if context_parts else str(img_tag)

# 3. åˆ†æsourceæ ‡ç­¾ä¸­çš„å›¾ç‰‡ï¼ˆé‡ç‚¹ï¼ï¼‰
print(f"\n=== åˆ†æå‰10ä¸ªsourceæ ‡ç­¾ ===")
source_docs = []
source_format_stats = {}

for i, source in enumerate(all_sources[:10]):
    print(f"\n--- Source {i+1} ---")
    
    srcset = source.get('srcset', '')
    if not srcset:
        print("æ²¡æœ‰æ‰¾åˆ°srcsetå±æ€§")
        continue
    
    print(f"Srcset: {srcset}")
    
    # è§£æsrcsetï¼Œå¯èƒ½åŒ…å«å¤šä¸ªURL
    urls = []
    for part in srcset.split(','):
        url_part = part.strip().split(' ')[0]  # å»æ‰ "2x" ç­‰æè¿°ç¬¦
        if url_part.startswith('/'):
            url_part = urljoin(base_url, url_part)
        urls.append(url_part)
    
    print(f"è§£æå‡ºçš„URLs: {urls}")
    
    for url in urls:
        img_format = get_image_format(url)
        print(f"æ ¼å¼: {img_format}, URL: {url}")
        
        source_format_stats[img_format] = source_format_stats.get(img_format, 0) + 1
        
        context = extract_context_from_source(source)
        print(f"ä¸Šä¸‹æ–‡: {context[:200]}...")

print(f"\n=== Sourceæ ‡ç­¾æ ¼å¼ç»Ÿè®¡ï¼ˆå‰10ä¸ªï¼‰===")
for fmt, count in sorted(source_format_stats.items()):
    print(f"{fmt}: {count} å¼ ")

# 3. åˆ†æå’Œæ”¶é›†æ‰€æœ‰å›¾ç‰‡
docs = []
format_stats = {}
sample_urls = {}

for i, img in enumerate(all_imgs[:10]):  # å…ˆçœ‹å‰10ä¸ªä½œä¸ºæ ·æœ¬
    print(f"\n--- å›¾ç‰‡ {i+1} ---")
    
    # è·å–å›¾ç‰‡URL
    raw = img.get('src') or img.get('data-src') or img.get('data-lazy-src') or img.get('data-srcset')
    
    if not raw:
        print("æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡URL")
        continue
    
    print(f"åŸå§‹URLå±æ€§: {raw}")
    
    # å¤„ç†å¯èƒ½çš„å¤šä¸ªURLï¼ˆsrcsetï¼‰
    urls = []
    for part in raw.split(','):
        u = part.strip().split(' ')[0]
        if u.startswith('//'):
            u = 'https:' + u
        elif u.startswith('/'):
            u = urljoin(base_url, u)
        urls.append(u)
    
    print(f"å¤„ç†åçš„URL: {urls}")
    
    # åˆ†ææ¯ä¸ªURL
    for url in urls:
        img_format = get_image_format(url)
        print(f"æ ¼å¼: {img_format}, URL: {url}")
        
        # ç»Ÿè®¡æ ¼å¼
        format_stats[img_format] = format_stats.get(img_format, 0) + 1
        
        # ä¿å­˜æ ·æœ¬URL
        if img_format not in sample_urls:
            sample_urls[img_format] = url
        
        # æå–ä¸Šä¸‹æ–‡
        context = extract_context(img)
        print(f"ä¸Šä¸‹æ–‡: {context[:200]}...")
        
        # åˆ›å»ºæ–‡æ¡£
        doc = Document(
            page_content=context,
            metadata={
                'img_url': url,
                'img_format': img_format,
                'alt_text': img.get('alt', ''),
                'title': img.get('title', ''),
                'class': ' '.join(img.get('class', [])),
                'original_tag': str(img)
            }
        )
        docs.append(doc)

print(f"\n=== æ ¼å¼ç»Ÿè®¡ï¼ˆå‰10å¼ å›¾ç‰‡çš„æ ·æœ¬ï¼‰===")
for fmt, count in sorted(format_stats.items()):
    print(f"{fmt}: {count} å¼ ")
    if fmt in sample_urls:
        print(f"  æ ·æœ¬URL: {sample_urls[fmt]}")

# 4. å¤„ç†æ‰€æœ‰å›¾ç‰‡å’Œsourceæ ‡ç­¾
print(f"\n=== å¤„ç†æ‰€æœ‰å›¾ç‰‡å’Œsourceæ ‡ç­¾ ===")
all_docs = []
all_format_stats = {}
jpg_docs = []

# å¤„ç†imgæ ‡ç­¾
for img in all_imgs:
    raw = img.get('src') or img.get('data-src') or img.get('data-lazy-src') or img.get('data-srcset')
    if not raw:
        continue
    
    for part in raw.split(','):
        u = part.strip().split(' ')[0]
        if u.startswith('//'):
            u = 'https:' + u
        elif u.startswith('/'):
            u = urljoin(base_url, u)
        
        img_format = get_image_format(u)
        all_format_stats[img_format] = all_format_stats.get(img_format, 0) + 1
        
        context = extract_context(img)
        
        doc = Document(
            page_content=context,
            metadata={
                'img_url': u,
                'img_format': img_format,
                'alt_text': img.get('alt', ''),
                'title': img.get('title', ''),
                'class': ' '.join(img.get('class', [])),
                'source_type': 'img'
            }
        )
        
        all_docs.append(doc)
        
        if img_format == 'jpg':
            jpg_docs.append(doc)

# å¤„ç†sourceæ ‡ç­¾ï¼ˆé‡ç‚¹ï¼ï¼‰
for source in all_sources:
    srcset = source.get('srcset', '')
    if not srcset:
        continue
    
    # è§£æsrcset
    for part in srcset.split(','):
        url_part = part.strip().split(' ')[0]  # å»æ‰ "2x" ç­‰æè¿°ç¬¦
        if url_part.startswith('/'):
            url_part = urljoin(base_url, url_part)
        
        img_format = get_image_format(url_part)
        all_format_stats[img_format] = all_format_stats.get(img_format, 0) + 1
        
        context = extract_context_from_source(source)
        
        # å°è¯•ä»å…³è”çš„picture/imgè·å–æ›´å¤šä¿¡æ¯
        picture = source.find_parent('picture')
        alt_text = ''
        title_text = ''
        class_attr = ''
        
        if picture:
            img_in_picture = picture.find('img')
            if img_in_picture:
                alt_text = img_in_picture.get('alt', '')
                title_text = img_in_picture.get('title', '')
                class_attr = ' '.join(img_in_picture.get('class', []))
        
        doc = Document(
            page_content=context,
            metadata={
                'img_url': url_part,
                'img_format': img_format,
                'alt_text': alt_text,
                'title': title_text,
                'class': class_attr,
                'source_type': 'source',
                'media': source.get('media', '')
            }
        )
        
        all_docs.append(doc)
        
        if img_format == 'jpg':
            jpg_docs.append(doc)

print(f"æ€»å…±å¤„ç†äº† {len(all_docs)} ä¸ªå›¾ç‰‡æ–‡æ¡£")
print(f"å…¶ä¸­JPGæ ¼å¼: {len(jpg_docs)} ä¸ª")

print("\n=== å®Œæ•´æ ¼å¼ç»Ÿè®¡ ===")
for fmt, count in sorted(all_format_stats.items()):
    print(f"{fmt}: {count} å¼ ")

# 5. å¦‚æœæœ‰JPGï¼Œæ˜¾ç¤ºJPGæ ·æœ¬
if jpg_docs:
    print(f"\n=== JPGå›¾ç‰‡æ ·æœ¬ ===")
    for i, doc in enumerate(jpg_docs[:5]):  # æ˜¾ç¤ºå‰5ä¸ªJPG
        print(f"\nJPG {i+1}:")
        print(f"æ¥æº: {doc.metadata['source_type']}")
        print(f"URL: {doc.metadata['img_url']}")
        print(f"Alt: {doc.metadata.get('alt_text', 'N/A')}")
        if doc.metadata.get('media'):
            print(f"Media: {doc.metadata['media']}")
        print(f"Context: {doc.page_content[:300]}...")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«pencilç›¸å…³å†…å®¹
        content_lower = doc.page_content.lower()
        if 'pencil' in content_lower or 'ipad' in content_lower:
            print(f"*** å¯èƒ½ç›¸å…³å†…å®¹ï¼åŒ…å«å…³é”®è¯ ***")
else:
    print(f"\n=== æ²¡æœ‰æ‰¾åˆ°JPGå›¾ç‰‡ï¼===")
    print("å¯èƒ½çš„åŸå› :")
    print("1. sourceæ ‡ç­¾ä¸­çš„URLè·¯å¾„è§£ææœ‰é—®é¢˜")
    print("2. éœ€è¦æ£€æŸ¥æ›´å¤šçš„å±æ€§")
    
    # æ£€æŸ¥ä¸€äº›åŸå§‹sourceæ ‡ç­¾
    print(f"\n=== åŸå§‹sourceæ ‡ç­¾æ ·æœ¬ ===")
    for i, source in enumerate(all_sources[:3]):
        print(f"\nSource {i+1}:")
        print(f"å®Œæ•´æ ‡ç­¾: {source}")
        srcset = source.get('srcset', '')
        if srcset:
            print(f"Srcset: {srcset}")
            for part in srcset.split(','):
                url_part = part.strip().split(' ')[0]
                print(f"  è§£æURL: {url_part}")
                if url_part.startswith('/'):
                    full_url = urljoin(base_url, url_part)
                    print(f"  å®Œæ•´URL: {full_url}")
                    print(f"  æ ¼å¼: {get_image_format(full_url)}")

# 6. æ£€æŸ¥æ˜¯å¦æœ‰åŒ…å«"pencil"æˆ–"ipad"çš„å†…å®¹
print(f"\n=== æœç´¢åŒ…å«å…³é”®è¯çš„å†…å®¹ ===")
pencil_docs = []
ipad_docs = []

for doc in all_docs:
    content_lower = doc.page_content.lower()
    url_lower = doc.metadata['img_url'].lower()
    alt_lower = doc.metadata.get('alt_text', '').lower()
    
    if 'pencil' in content_lower or 'pencil' in url_lower or 'pencil' in alt_lower:
        pencil_docs.append(doc)
    
    if 'ipad' in content_lower or 'ipad' in url_lower or 'ipad' in alt_lower:
        ipad_docs.append(doc)

print(f"åŒ…å«'pencil'çš„æ–‡æ¡£: {len(pencil_docs)}")
print(f"åŒ…å«'ipad'çš„æ–‡æ¡£: {len(ipad_docs)}")

if pencil_docs:
    print(f"\n=== Pencilç›¸å…³å†…å®¹æ ·æœ¬ ===")
    for i, doc in enumerate(pencil_docs[:3]):
        print(f"\nPencilç›¸å…³ {i+1}:")
        print(f"æ ¼å¼: {doc.metadata['img_format']}")
        print(f"æ¥æº: {doc.metadata['source_type']}")
        print(f"URL: {doc.metadata['img_url']}")
        print(f"Alt: {doc.metadata.get('alt_text', 'N/A')}")
        print(f"Context: {doc.page_content[:200]}...")

if ipad_docs:
    print(f"\n=== iPadç›¸å…³å†…å®¹æ ·æœ¬ ===")
    for i, doc in enumerate(ipad_docs[:3]):
        print(f"\niPadç›¸å…³ {i+1}:")
        print(f"æ ¼å¼: {doc.metadata['img_format']}")
        print(f"æ¥æº: {doc.metadata['source_type']}")
        print(f"URL: {doc.metadata['img_url']}")
        print(f"Alt: {doc.metadata.get('alt_text', 'N/A')}")
        print(f"Context: {doc.page_content[:200]}...")

# 7. åˆ›å»ºå‘é‡å­˜å‚¨å¹¶æä¾›äº¤äº’å¼æŸ¥è¯¢
if len(all_docs) > 0:
    print(f"\n=== åˆ›å»ºå‘é‡å­˜å‚¨ ===")
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    
    chroma_all = Chroma.from_documents(
        all_docs,
        embedding=embeddings,
        collection_name='apple_images_debug'
    )
    
    print(f"å‘é‡å­˜å‚¨åˆ›å»ºå®Œæˆï¼åŒ…å« {len(all_docs)} ä¸ªå›¾ç‰‡æ–‡æ¡£")
    print(f"å…¶ä¸­JPGæ ¼å¼: {len(jpg_docs)} ä¸ª")
    
    # ç»Ÿè®¡PNGæ–‡æ¡£
    png_docs = [doc for doc in all_docs if doc.metadata['img_format'] == 'png']
    print(f"å…¶ä¸­PNGæ ¼å¼: {len(png_docs)} ä¸ª")
    
    # äº¤äº’å¼æŸ¥è¯¢ç³»ç»Ÿ
    print(f"\n=== äº¤äº’å¼å›¾ç‰‡æœç´¢ ===")
    print("è¾“å…¥æŸ¥è¯¢æ¥æœç´¢ç›¸å…³å›¾ç‰‡ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰")
    print("\nğŸ” æœç´¢æ ¼å¼:")
    print("  your_query          - æœç´¢æ‰€æœ‰æ ¼å¼ï¼ˆä¼˜å…ˆJPG/PNGï¼‰")
    print("  jpg:your_query      - ä»…æœç´¢JPGæ ¼å¼")
    print("  png:your_query      - ä»…æœç´¢PNGæ ¼å¼")
    print("  jpg+png:your_query  - ä»…æœç´¢JPGå’ŒPNGæ ¼å¼")
    print("\nğŸ’¡ ç¤ºä¾‹æŸ¥è¯¢:")
    print("  apple pencil")
    print("  jpg:iPad Pro")
    print("  png:iPhone camera")
    print("  jpg+png:MacBook Air")
    
    while True:
        user_input = input("\nè¯·è¾“å…¥æœç´¢æŸ¥è¯¢: ").strip()
        
        if user_input.lower() == 'quit':
            print("é€€å‡ºæœç´¢ã€‚å†è§ï¼")
            break
            
        if not user_input:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æœç´¢æŸ¥è¯¢ã€‚")
            continue
        
        # è§£ææœç´¢æ ¼å¼å’ŒæŸ¥è¯¢
        format_filter = None
        query = user_input
        
        if user_input.startswith('jpg:'):
            format_filter = ['jpg']
            query = user_input[4:].strip()
        elif user_input.startswith('png:'):
            format_filter = ['png']
            query = user_input[4:].strip()
        elif user_input.startswith('jpg+png:'):
            format_filter = ['jpg', 'png']
            query = user_input[8:].strip()
        
        if not query:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æœç´¢æŸ¥è¯¢è¯ã€‚")
            continue
        
        # æ˜¾ç¤ºæœç´¢ä¿¡æ¯
        if format_filter:
            format_str = " + ".join(format_filter).upper()
            print(f"\næ­£åœ¨æœç´¢ {format_str} æ ¼å¼çš„å›¾ç‰‡: '{query}'...")
        else:
            print(f"\næ­£åœ¨æœç´¢æ‰€æœ‰æ ¼å¼çš„å›¾ç‰‡: '{query}' (ä¼˜å…ˆJPG/PNG)...")
        
        # æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢
        results = chroma_all.similarity_search_with_score(query, k=30)  # è·å–æ›´å¤šç»“æœç”¨äºè¿‡æ»¤
        
        # å¤„ç†å’Œè¿‡æ»¤ç»“æœ
        processed_results = []
        
        for doc, score in results:
            img_format = doc.metadata['img_format']
            
            # åº”ç”¨æ ¼å¼è¿‡æ»¤
            if format_filter and img_format not in format_filter:
                continue
            
            img_info = {
                'url': doc.metadata['img_url'],
                'format': img_format,
                'alt_text': doc.metadata.get('alt_text', ''),
                'title': doc.metadata.get('title', ''),
                'source_type': doc.metadata['source_type'],
                'media': doc.metadata.get('media', ''),
                'score': score,
                'context': doc.page_content
            }
            processed_results.append(img_info)
        
        # æ’åºç»“æœï¼šå¦‚æœæ²¡æœ‰æŒ‡å®šæ ¼å¼è¿‡æ»¤ï¼Œä¼˜å…ˆJPGå’ŒPNG
        if not format_filter:
            # ä¼˜å…ˆJPGï¼Œç„¶åPNGï¼Œç„¶åå…¶ä»–æ ¼å¼ï¼Œæœ€åæŒ‰åˆ†æ•°æ’åº
            processed_results.sort(key=lambda x: (
                x['format'] not in ['jpg', 'png'],  # ä¼˜å…ˆJPG/PNG
                x['format'] != 'jpg',               # JPGä¼˜å…ˆäºPNG
                x['score']                          # æŒ‰åˆ†æ•°æ’åº
            ))
        else:
            # å¦‚æœæŒ‡å®šäº†æ ¼å¼ï¼ŒåªæŒ‰åˆ†æ•°æ’åº
            processed_results.sort(key=lambda x: x['score'])
        
        # è¿”å›å‰5ä¸ªç»“æœ
        top_5 = processed_results[:5]
        
        if not top_5:
            if format_filter:
                format_str = " + ".join(format_filter).upper()
                print(f"âŒ æ²¡æœ‰æ‰¾åˆ° {format_str} æ ¼å¼çš„ç›¸å…³å›¾ç‰‡")
                print("ğŸ’¡ å»ºè®®:")
                print("  - å°è¯•ä¸åŒçš„æŸ¥è¯¢è¯")
                print("  - ç§»é™¤æ ¼å¼é™åˆ¶æœç´¢æ‰€æœ‰æ ¼å¼")
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å›¾ç‰‡")
            continue
        
        print(f"\næ‰¾åˆ° {len(processed_results)} ä¸ªç›¸å…³ç»“æœï¼Œæ˜¾ç¤ºå‰5ä¸ª:")
        print("=" * 80)
        
        for i, img in enumerate(top_5, 1):
            print(f"\nã€å›¾ç‰‡ {i}ã€‘")
            print(f"URL: {img['url']}")
            
            # æ ¹æ®æ ¼å¼æ·»åŠ æ ‡è¯†
            format_display = img['format'].upper()
            if img['format'] == 'jpg':
                format_display += " âœ…"
            elif img['format'] == 'png':
                format_display += " ğŸŸ¢"
            
            print(f"æ ¼å¼: {format_display}")
            print(f"ç›¸ä¼¼åº¦åˆ†æ•°: {img['score']:.4f}")
            
            if img['alt_text']:
                print(f"Altæ–‡æœ¬: {img['alt_text']}")
            
            if img['title']:
                print(f"æ ‡é¢˜: {img['title']}")
            
            if img['media']:
                print(f"åª’ä½“æŸ¥è¯¢: {img['media']}")
            
            print(f"æ¥æº: {img['source_type']} æ ‡ç­¾")
            
            # æ˜¾ç¤ºç›¸å…³ä¸Šä¸‹æ–‡ï¼ˆæˆªå–é‡è¦éƒ¨åˆ†ï¼‰
            context = img['context']
            if len(context) > 200:
                context = context[:200] + "..."
            print(f"ä¸Šä¸‹æ–‡: {context}")
            
            print("-" * 60)
        
        # ç»Ÿè®¡ä¿¡æ¯
        format_count = {}
        for img in top_5:
            fmt = img['format']
            format_count[fmt] = format_count.get(fmt, 0) + 1
        
        print(f"\nğŸ“Š ç»“æœæ ¼å¼åˆ†å¸ƒ: {dict(format_count)}")
        
        # æä¾›å»ºè®®
        jpg_count = format_count.get('jpg', 0)
        png_count = format_count.get('png', 0)
        
        if format_filter:
            format_str = " + ".join(format_filter).upper()
            print(f"âœ… æˆåŠŸæ‰¾åˆ° {len(top_5)} ä¸ª {format_str} æ ¼å¼çš„å›¾ç‰‡")
        else:
            total_hq = jpg_count + png_count
            if total_hq == 0:
                print("\nğŸ’¡ æç¤º: æ²¡æœ‰æ‰¾åˆ°JPG/PNGæ ¼å¼çš„å›¾ç‰‡ã€‚ä½ å¯ä»¥å°è¯•:")
                print("  - æ›´å…·ä½“çš„æŸ¥è¯¢è¯")
                print("  - ä½¿ç”¨ 'jpg:æŸ¥è¯¢è¯' æˆ– 'png:æŸ¥è¯¢è¯' æ¥ä¸“é—¨æœç´¢")
            else:
                print(f"\nâœ… æ‰¾åˆ° {total_hq} ä¸ªé«˜è´¨é‡å›¾ç‰‡ (JPG: {jpg_count}, PNG: {png_count})")

else:
    print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡æ¡£ï¼")